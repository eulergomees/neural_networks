{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Atividade: Perceptron para classificação de petroleo\n",
    "**INSTITUTO FEDERAL DE MINAS GERIAS**\n",
    "*Departamento de Engenharia e Computação*\n",
    "\n",
    "**Professor:** Ciniro Nametala\n",
    "\n",
    "**Aluno:** Euler Gomes\n"
   ],
   "id": "305393bd4b8d7c9b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#importando bibliotecas\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import plotly.graph_objects as go\n"
   ],
   "id": "dd8021f7e1be3555",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Funções de ativação",
   "id": "805d888663f7e6c0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#funcoes de ativacao\n",
    "#funcao degrau bipolar\n",
    "def degrau_bipolar(x):\n",
    "    if x > 0:\n",
    "        y = 1\n",
    "    else: # Trata x <= 0\n",
    "        y = -1\n",
    "    return y\n",
    "\n",
    "#funcao de previsao\n",
    "def previsao (w,x):\n",
    "    u = np.dot(w.T,x)\n",
    "    yhat = degrau_bipolar(u)\n",
    "    return yhat"
   ],
   "id": "194264f02e208ee6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Implementação do Perceptron",
   "id": "1e9f4f5adfcd0baf"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#leitura do dataset de treino\n",
    "data = pd.read_csv('dataset/dataset_oil_training.csv', sep=';')\n",
    "print(data.head())"
   ],
   "id": "b9dc8ca63859e0a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#quatidade de elementos na amostra\n",
    "n_amostras = data.shape[0]\n",
    "\n",
    "#quantidade de variaveis de entrada (subtrair a coluna de tipos)\n",
    "n_variaveis = 3\n",
    "\n",
    "#separando os dados contendo apenas as variaveis de entrada\n",
    "x = data.iloc[:, 1:4].values\n",
    "print(x)"
   ],
   "id": "c8ef6e9140a5cfb9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#inserindo o bias\n",
    "bias = np.ones((n_amostras, 1)) * -1\n",
    "\n",
    "#concatenar o bias com o dataset x\n",
    "x = np.hstack((x, bias))\n",
    "print(x)"
   ],
   "id": "3038159857fb79d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#associar cada entrada xi com cada saída y\n",
    "y = data.iloc[:, 4].values\n",
    "print(y)\n",
    "\n",
    "#contar quantas amostras de cada classe existem no dataset\n",
    "print(f\"-1: {(y == -1).sum()}\")\n",
    "print(f\"1: {(y == 1).sum()}\")"
   ],
   "id": "db18b0bfef7e293",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Inicialização do perceptron",
   "id": "aa9a06c3d3cfa37e"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#inicializar o vetor de pesos W com valores aleatorios\n",
    "w = np.random.uniform(-1,1, n_variaveis + 1)\n",
    "print(w)"
   ],
   "id": "b37a553366cde3b5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#taxa de aprendizagem\n",
    "eta = 0.7\n",
    "\n",
    "#tolerancia\n",
    "tolerancia = 0.01\n",
    "\n",
    "#erro inicial\n",
    "erro_medio = tolerancia + 1\n",
    "\n",
    "#vetor de erro medio por epoca\n",
    "erros_epocas = []\n",
    "\n",
    "#contador de epocas\n",
    "epoca = 0\n",
    "\n",
    "#maximo de epocas para treino\n",
    "max_epocas = 2000"
   ],
   "id": "b19f5432b5143476",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "#criterios de parada\n",
    "criterio_erro = True\n",
    "criterio_epocas = True\n",
    "\n",
    "while criterio_erro == True and criterio_epocas == True:\n",
    "    erro_atual = 0\n",
    "    epoca = epoca + 1\n",
    "\n",
    "    #embaralhar os indices\n",
    "    ind_embaralhados = np.random.permutation(n_amostras)\n",
    "\n",
    "    for i in range(n_amostras):\n",
    "        indice_amostra = ind_embaralhados[i]\n",
    "        xi_amostra = x[indice_amostra, :]\n",
    "\n",
    "        #potencial e ativacao\n",
    "        u = np.dot(w.T, xi_amostra)\n",
    "\n",
    "        yhat = degrau_bipolar(u)\n",
    "\n",
    "        e = y[indice_amostra] - yhat\n",
    "\n",
    "        w = w + (eta * e) * xi_amostra\n",
    "\n",
    "        erro_atual = erro_atual + np.abs(e)\n",
    "\n",
    "    erro_medio = erro_atual / n_amostras\n",
    "    erros_epocas.append(erro_medio)\n",
    "\n",
    "    if erro_medio < tolerancia:\n",
    "            criterio_erro = False\n",
    "    if epoca > max_epocas:\n",
    "            criterio_epocas = False\n"
   ],
   "id": "c7cb33e7cf2d1171",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.figure(figsize = (10,4))\n",
    "plt.plot(erros_epocas)\n",
    "plt.title('Convergência do erro')\n",
    "plt.xlabel('Épocas')\n",
    "plt.ylabel('Erro médio')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ],
   "id": "9e22b84389485ead",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "print('Conjunto ideal de pesos w*')\n",
    "print(w)\n",
    "\n",
    "print('Quantidade de épocas necessárias')\n",
    "print(epoca)\n",
    "\n",
    "yhat_display = np.where(yhat == -1, 0, yhat)\n",
    "y_display = np.where(y == -1, 0, y)\n",
    "\n",
    "acuracia = (np.sum(yhat_display == y_display) / n_amostras) * 100\n",
    "print(acuracia)"
   ],
   "id": "a5c7bbf9864d9542",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Treino |          Pesos iniciais - W0 W1 W2 W3          |            Pesos finais - W0 W1 W2 W3            |\n",
    "|--------|:----------------------------------------------:|:------------------------------------------------:|\n",
    "| 1      |  0.59299181 0.34039827 0.54534365 0.51558908   | 3.97607181  8.25801827 -3.40003635 -6.684410923  |\n",
    "| 2      |  -0.9415994   0.15183702  0.73735886 -0.93399  |   2.6718206   8.64543702 -3.23728114 -6.93399    |\n",
    "| 3      | 0.89861555 -0.81599297  0.68705831 -0.64087316 |  4.61411555  9.00170703 -0.73244169 -7.24087316  |\n",
    "| 4      | 0.85012439 -0.65550559  0.73160074  0.23060695 |  2.14502439  8.38047441 -2.43137926 -6.16939305  |\n",
    "| 5      | 0.77303616  0.70334684 -0.394745   -0.57397204 |  3.17121616  8.86150684 -3.259425   -5.97397204  |"
   ],
   "id": "6381a63ab6eea8b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "data_test = pd.read_csv('dataset/dataset_oil_test.csv', sep=';')\n",
    "\n",
    "n_variaveis_test = 3\n",
    "\n",
    "n_amostras_test = data_test.shape[0]\n",
    "\n",
    "x_test = data.iloc[:, 1:4].values\n",
    "print(x)\n",
    "\n",
    "x_test = np.hstack((x_test, bias))\n",
    "print(x_test)"
   ],
   "id": "c7cb62a81c4b1642",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_previsto_test = np.zeros(n_amostras_test)\n",
    "for i in range(n_amostras_test):\n",
    "    y_previsto_test[i] = previsao(w, x_test[i])\n",
    "\n",
    "    amostra_id = data_test.iloc[i, 0]\n",
    "\n",
    "    print(f\"Amostra {amostra_id}, Valor Previsto = {y_previsto_test[i]}\")"
   ],
   "id": "5086d3b6e062dae7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "| Amostra |   $X_1$ |   $X_2$ |  $X_3$ | $\\hat{Y}(T_1)$ | $\\hat{Y}(T_2)$ | $\\hat{Y}(T_3)$ | $\\hat{Y}(T_4)$ | $\\hat{Y}(T_5)$ |\n",
    "|:--------|--------:|--------:|-------:|:---------------|:---------------|:---------------|:---------------|:---------------|\n",
    "| 1       | -0,3665 |  0,0620 | 5,9891 | -1             | -1             | -1             | -1             | 1              |\n",
    "| 2       | -0,7842 |  1,1267 | 5,5912 | 1              | 1              | 1              | 1              | 1              |\n",
    "| 3       |  0,3012 |  0,5611 | 5,8234 | 1              | -1             | 1              | 1              | 1              |\n",
    "| 4       |  0,7757 |  1,0648 | 8,0677 | -1             | -1             | -1             | -1             | 1              |\n",
    "| 5       |  0,1570 |  0,8028 | 6,3040 | 1              | -1             | 1              | 1              | 1              |\n",
    "| 6       | -0,7014 |  1,0316 | 3,6005 | 1              | -1             | 1              | -1             | 1              |\n",
    "| 7       |  0,3748 |  0,1536 | 6,1537 | -1             | -1             | 1              | 1              | 1              |\n",
    "| 8       | -0,6920 |  0,9404 | 4,4058 | 1              | -1             | -1             | -1             | 1              |\n",
    "| 9       | -1,3970 |  0,7141 | 4,9263 | 1              | 1              | 1              | 1              | 1              |\n",
    "| 10      | -1,8842 | -0,2805 | 1,2548 | 1              | -1             | 1              | 1              | 1              |"
   ],
   "id": "ae0ae76b6d561cd3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Qual foi sua taxa de acerto percentual para cada modelo?\n",
    "54% de acerto com 2000 epocas\n",
    "\n",
    "### Qual o efeito de aumentar ou diminuir o número de épocas na qualidade dos resultados?\n",
    "Nenhum, o gráfico de erro demonstra que a função não converge mesmo aumentando as épocas.\n",
    "\n",
    "### Qual o efeito de aumentar ou diminuir a taxa de aprendizagem na qualidade dos resultados?\n",
    "Nenhum, aumentar ou diminuir a taxa de aprendizagem mostrou resultados muito parecidos.\n",
    "\n",
    "### Discorra se é possível afirmar se as suas classes, neste problema, são linearmente separáveis.\n",
    "Não é possivél separar linearmente essas duas classes, por isso o perceptron básico não é capaz de classificar corretamente 100% das amostras mesmo ajustando as variaveis de taxa de aprendizado e de epocas."
   ],
   "id": "36820ee1bf2ef807"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
